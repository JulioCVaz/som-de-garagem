"use strict";
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };
        return extendStatics(d, b);
    }
    return function (d, b) {
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
Object.defineProperty(exports, "__esModule", { value: true });
var AbstractTokenizer_1 = require("./AbstractTokenizer");
var _1 = require("./");
var then_read_stream_1 = require("then-read-stream");
var es6_promise_1 = require("es6-promise");
var _debug = require("debug");
var debug = _debug("strtok3:ReadStreamTokenizer");
var ReadStreamTokenizer = /** @class */ (function (_super) {
    __extends(ReadStreamTokenizer, _super);
    function ReadStreamTokenizer(stream, fileSize) {
        var _this = _super.call(this) || this;
        _this.streamReader = new then_read_stream_1.StreamReader(stream);
        _this.fileSize = fileSize;
        return _this;
    }
    /**
     * Read buffer from stream
     * @param buffer
     * @param offset is the offset in the buffer to start writing at; if not provided, start at 0
     * @param length is an integer specifying the number of bytes to read
     * @returns Promise number of bytes read
     */
    ReadStreamTokenizer.prototype.readBuffer = function (buffer, offset, length, position) {
        var _this = this;
        if (offset === void 0) { offset = 0; }
        if (length === void 0) { length = buffer.length; }
        if (length === 0) {
            return es6_promise_1.Promise.resolve(0);
        }
        if (position) {
            if (position > this.position) {
                return this.ignore(position - this.position).then(function () {
                    return _this.readBuffer(buffer, offset, length);
                });
            }
            else {
                throw new Error('Cannot read from a negative offset in a stream');
            }
        }
        if (position) {
            if (position > this.position) {
                return this.ignore(position - this.position).then(function () {
                    return _this.readBuffer(buffer, offset, length);
                });
            }
            else {
                throw new Error('Cannot read from a negative offset in a stream');
            }
        }
        return this.streamReader.read(buffer, offset, length)
            .then(function (bytesRead) {
            _this.position += bytesRead;
            return bytesRead;
        })
            .catch(function (err) {
            if (err.message === then_read_stream_1.endOfStream) // Convert EndOfStream into EndOfFile
                throw new Error(_1.endOfFile);
            else
                throw err;
        });
    };
    /**
     * Peek (read ahead) buffer from tokenizer
     * @param buffer
     * @param offset is the offset in the buffer to start writing at; if not provided, start at 0
     * @param length is an integer specifying the number of bytes to read
     * @param position is an integer specifying where to begin reading from in the file. If position is null, data will be read from the current file position.
     * @returns {Promise<TResult|number>}
     */
    ReadStreamTokenizer.prototype.peekBuffer = function (buffer, offset, length) {
        if (offset === void 0) { offset = 0; }
        if (length === void 0) { length = buffer.length; }
        return this.streamReader.peek(buffer, offset, length)
            .catch(function (err) {
            if (err.message === then_read_stream_1.endOfStream) // Convert EndOfStream into EndOfFile
                throw new Error(_1.endOfFile);
            else
                throw err;
        });
    };
    ReadStreamTokenizer.prototype.ignore = function (length) {
        debug("Ignore " + length + " bytes in a stream");
        var buf = Buffer.alloc(length);
        return this.readBuffer(buf); // Stream cannot skip data
    };
    return ReadStreamTokenizer;
}(AbstractTokenizer_1.AbstractTokenizer));
exports.ReadStreamTokenizer = ReadStreamTokenizer;
